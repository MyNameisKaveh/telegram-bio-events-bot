import asyncio
import re
import logging
from datetime import datetime
import aiohttp
import feedparser
from telegram import Bot
# from telegram.ext import Application # Ø§Ú¯Ø± Application Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø­Ø°Ù Ú©Ø±Ø¯
import os
from dataclasses import dataclass, field # field Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
from typing import List, Optional
# import json # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ processed_items.json Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø´ÙˆØ¯ØŒ Ø§ÛŒÙ† Ø¯ÛŒÚ¯Ø± Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª
from aiohttp import web

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class EventInfo:
    """Class to store event information"""
    title: str
    description: str  # Ø§ÛŒÙ† Ù‡Ù…Ú†Ù†Ø§Ù† HTML Ø®Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯
    link: str
    published: str
    source_channel: str  # Ù†Ø§Ù… Ù†Ù…Ø§ÛŒØ´ÛŒ Ú©Ø§Ù†Ø§Ù„
    source_channel_username: Optional[str] = None # Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú©


class EventDetector:
    """Class to detect events in RSS feed content"""

    EVENT_KEYWORDS = [
        'ÙˆØ¨ÛŒÙ†Ø§Ø±', 'webinar', 'Ú©Ø§Ø±Ú¯Ø§Ù‡', 'workshop', 'Ø³Ù…ÛŒÙ†Ø§Ø±', 'seminar',
        'Ú©Ù†ÙØ±Ø§Ù†Ø³', 'conference', 'Ù‡Ù…Ø§ÛŒØ´', 'congress', 'Ù†Ø´Ø³Øª', 'meeting',
        'Ø¯ÙˆØ±Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ', 'course', 'Ú©Ù„Ø§Ø³', 'class', 'Ø§ÛŒÙˆÙ†Øª', 'event',
        'Ø¨Ø±Ú¯Ø²Ø§Ø±', 'organize', 'Ø´Ø±Ú©Øª', 'participate', 'Ø«Ø¨Øª Ù†Ø§Ù…', 'register',
        'Ø±Ø§ÛŒÚ¯Ø§Ù†', 'free', 'Ø¢Ù†Ù„Ø§ÛŒÙ†', 'online', 'Ù…Ø¬Ø§Ø²ÛŒ', 'virtual',
        'Ø¢Ù…ÙˆØ²Ø´', 'training', 'ÙØ±Ø§Ø®ÙˆØ§Ù†', 'call', 'Ú¯ÙˆØ§Ù‡ÛŒ', 'certificate',
        'Ù…Ø¯Ø±Ú©', 'certification', 'Ù„Ø§ÛŒÙˆ', 'live'
    ]

    def detect_event(self, title: str, description_html: str) -> bool: # Ø§Ù…Ø¶Ø§ÛŒ Ù…ØªØ¯ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯
        """Detect if content contains event information based on title and HTML description."""
        # ÛŒÚ© Ù†Ø³Ø®Ù‡ ÙÙ‚Ø· Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†ÛŒØ¯
        text_only_description = re.sub(r'<[^>]+>', '', description_html).strip()
        full_text = f"{title} {text_only_description}" # Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù„Øµ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
        text_lower = full_text.lower()

        # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø·Ø§Ø¨Ù‚
        matches = sum(1 for keyword in self.EVENT_KEYWORDS if keyword in text_lower)

        # Ø§Ú¯Ø± Ø­Ø¯Ø§Ù‚Ù„ Û² Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ ÛŒØ§ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø®Ø§ØµÛŒ Ø¯Ø§Ø´ØªÛŒÙ…ØŒ True Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
        # Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ XML Ú©Ù‡ ÙØ±Ø³ØªØ§Ø¯ÛŒØ¯ØŒ Ø­ØªÛŒ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø«Ù„ "ÙˆØ¨ÛŒÙ†Ø§Ø±" ÛŒØ§ "Ø«Ø¨Øª Ù†Ø§Ù…" Ú©Ø§ÙÛŒ Ø¨Ø§Ø´Ø¯.
        # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ† Ù…Ù†Ø·Ù‚ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÛŒØ§Ø² Ø®ÙˆØ¯ØªØ§Ù† Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ú©Ù†ÛŒØ¯.
        # Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ØŒ Ø§Ú¯Ø± ÙÙ‚Ø· Ø­Ø¶ÙˆØ± "Ø«Ø¨Øª Ù†Ø§Ù…" ÛŒØ§ "ÙˆØ¨ÛŒÙ†Ø§Ø±" Ú©Ø§ÙÛŒ Ø§Ø³Øª:
        has_specific_pattern = any([
            'Ø«Ø¨Øª Ù†Ø§Ù…' in text_lower,
            'Ø´Ø±Ú©Øª Ø¯Ø±' in text_lower,
            'Ø¨Ø±Ú¯Ø²Ø§Ø± Ù…ÛŒ' in text_lower, # Ù…Ø±Ø§Ù‚Ø¨ Ø¨Ø§Ø´ÛŒØ¯ Ø§ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª False Positive Ø²ÛŒØ§Ø¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            'register' in text_lower,
            'join' in text_lower,
            'ÙˆØ¨ÛŒÙ†Ø§Ø±' in text_lower, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            'Ú©Ø§Ø±Ú¯Ø§Ù‡' in text_lower, # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
            'Ø¯ÙˆØ±Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†' in text_lower # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯
        ])

        # Ø§Ú¯Ø± ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ù‡ Ø­Ø¯ Ù†ØµØ§Ø¨ Ø±Ø³ÛŒØ¯ ÛŒØ§ ÛŒÚ©ÛŒ Ø§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø®ÛŒÙ„ÛŒ Ø®Ø§Øµ Ù¾ÛŒØ¯Ø§ Ø´Ø¯
        return matches >= 2 or has_specific_pattern


class RSSTelegramBot:
    """RSS-based Telegram Event Bot"""

    def __init__(self, bot_token: str, target_channel: str):
        self.bot_token = bot_token
        self.target_channel = target_channel
        self.bot = Bot(token=bot_token)
        self.detector = EventDetector()
        self.processed_items = set()  # To avoid duplicates (in-memory for now)

        self.rss_feeds = [
            {
                'name': 'WinCell Co',
                'url': 'https://rsshub.app/telegram/channel/wincellco',
                'channel': 'wincellco'
            },
            {
                'name': 'Rayazistazma',
                'url': 'https://rsshub.app/telegram/channel/Rayazistazma',
                'channel': 'Rayazistazma'
            },
            {
                'name': 'SBU Bio Society',
                'url': 'https://rsshub.app/telegram/channel/SBUBIOSOCIETY',
                'channel': 'SBUBIOSOCIETY'
            }
            # ÙÛŒØ¯Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
        ]

    async def fetch_feed(self, session: aiohttp.ClientSession, feed_info: dict) -> List[EventInfo]:
        """Fetch and parse RSS feed"""
        events = []
        feed_url = feed_info['url']
        feed_name = feed_info['name']
        logger.info(f"Fetching feed: {feed_name} from {feed_url}")

        try:
            async with session.get(feed_url, timeout=30) as response:
                if response.status == 200:
                    content = await response.text()
                    feed = feedparser.parse(content)
                    logger.info(f"Successfully fetched {feed_name}. Entries: {len(feed.entries)}")

                    for entry in feed.entries[:10]:  # Check last 10 entries
                        entry_id = f"{feed_info.get('channel', feed_name)}_{entry.get('id', entry.get('link', ''))}"

                        if entry_id not in self.processed_items:
                            raw_title = entry.get('title', '').strip()
                            raw_description_html = entry.get('description', entry.get('summary', ''))

                            # Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª HTML Ø®Ø§Ù… ØªØ´Ø®ÛŒØµ Ø¯Ù‡ÛŒØ¯
                            if self.detector.detect_event(raw_title, raw_description_html):
                                event = EventInfo(
                                    title=raw_title,
                                    description=raw_description_html, # HTML Ø®Ø§Ù… Ø§ÛŒÙ†Ø¬Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                                    link=entry.get('link', ''),
                                    published=entry.get('published', ''),
                                    source_channel=feed_name,
                                    source_channel_username=feed_info.get('channel') # Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ú©Ø§Ù†Ø§Ù„ Ù…Ù†Ø¨Ø¹
                                )
                                events.append(event)
                                self.processed_items.add(entry_id)
                                # Ø¹Ø¯Ù… Ø°Ø®ÛŒØ±Ù‡ processed_items Ø¯Ø± ÙØ§ÛŒÙ„ Ø·Ø¨Ù‚ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ÙØ¹Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø±

                        # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø¬Ù… processed_items Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…ØµØ±Ù Ø²ÛŒØ§Ø¯ Ø­Ø§ÙØ¸Ù‡
                        if len(self.processed_items) > 1000: # Ø§ÛŒÙ† Ø¹Ø¯Ø¯ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯
                            items_list = list(self.processed_items)
                            # Ø­Ø°Ù Û²Û°Û° Ø¢ÛŒØªÙ… Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¢Ø²Ø§Ø¯ Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡
                            self.processed_items = set(items_list[200:])
                            logger.info(f"Cleaned up processed_items. New size: {len(self.processed_items)}")
                else:
                    logger.error(f"Error fetching feed {feed_name}: Status {response.status} - {await response.text()}")

        except aiohttp.ClientConnectorError as e:
            logger.error(f"Connection error for {feed_name} ({feed_url}): {e}")
        except aiohttp.ClientTimeout as e:
            logger.error(f"Timeout error for {feed_name} ({feed_url}): {e}")
        except Exception as e:
            logger.error(f"Error fetching or parsing feed {feed_name} ({feed_url}): {e}", exc_info=True)

        return events

    def format_event_message(self, event: EventInfo) -> str:
        """Format event for Telegram with RTL and source linking."""
        RLM = "\u200F"  # Right-to-Left Mark

        # 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù†ÙˆØ§Ù†: Ø­Ø°Ù Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ ÛŒØ§ Ù¾ÛŒØ´ÙˆÙ†Ø¯Ù‡Ø§ Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª (ÙØ¹Ù„Ø§ Ø¯Ø³Øª Ù†Ø®ÙˆØ±Ø¯Ù‡)
        # Ø¹Ù†ÙˆØ§Ù†â€ŒÙ‡Ø§ÛŒ RSS Ú¯Ø§Ù‡ÛŒ Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ ğŸ–¼ (Ø¹Ú©Ø³) ÛŒØ§ ğŸ” (ÙÙˆØ±ÙˆØ§Ø±Ø¯) Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. ÙØ¹Ù„Ø§ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ….
        # Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² re.sub Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
        # Ù…Ø«Ø§Ù„: display_title = re.sub(r"^[ğŸ”ğŸ–¼\s]+", "", event.title).strip()
        display_title = event.title.strip()

        # 2. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªÙˆØ¶ÛŒØ­Ø§Øª: Ø­Ø°Ù HTMLØŒ Ø­Ø°Ù Ø®Ø· "Forwarded From"ØŒ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„
        raw_description_html = event.description
        # Ø§Ø¨ØªØ¯Ø§ ØªÙ…Ø§Ù… ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯ ØªØ§ Ù…ØªÙ† Ø®Ø§Ù„Øµ Ø¨Ù‡ Ø¯Ø³Øª Ø¢ÛŒØ¯
        text_content_from_html = re.sub(r'<[^>]+>', '', raw_description_html).strip()

        # Ø­Ø°Ù Ø®Ø· "Forwarded From" Ø§Ú¯Ø± Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ù…ØªÙ† Ø¨Ø§Ø´Ø¯
        lines = text_content_from_html.split('\n')
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø®Ø·ÙˆØ· Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Forwarded From
        # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ø§Ú¯Ø± ÙØ±Ù…Øª "Forwarded From" Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯
        cleaned_lines = []
        forwarded_line_found = False
        if lines and lines[0].lower().startswith("forwarded from "):
            # Ø§Ú¯Ø± Ø®Ø· Ø§ÙˆÙ„ "Forwarded From" Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ùˆ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ú†Ù†Ø¯ Ø®Ø· Ø¨Ø¹Ø¯ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±
            # Ø§ÛŒÙ† ÛŒÚ© ÙØ±Ø¶ Ø³Ø§Ø¯Ù‡ Ø§Ø³ØªØ› Ø´Ø§ÛŒØ¯ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            # Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ØŒ RSSHub Ú¯Ø§Ù‡ÛŒ ÛŒÚ© <p> Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Forwarded From Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±Ø¯.
            # Ø¨Ø§ Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ØŒ Ø§ÛŒÙ† Ø®Ø· Ø¨Ù‡ Ø§Ø¨ØªØ¯Ø§ÛŒ Ù…ØªÙ† Ù…ÛŒâ€ŒØ¢ÛŒØ¯.
            final_description = '\n'.join(lines[1:]).strip()
        else:
            final_description = text_content_from_html
        
        # Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù‡Ù†ÙˆØ² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± ÛŒØ§ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§ Ø¨Ø§Ø´Ù†Ø¯ Ú©Ù‡ Ø§Ø² Ù¾ÛŒØ§Ù… Ø§ØµÙ„ÛŒ Ù‡Ø³ØªÙ†Ø¯
        # Ø§Ú¯Ø± ØªÙˆØ¶ÛŒØ­Ø§Øª Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³ØªØŒ Ø¢Ù† Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ú©Ù†ÛŒØ¯
        final_description = final_description.strip()
        if len(final_description) > 500: # Ø·ÙˆÙ„ Ø±Ø§ Ú©Ù…ÛŒ Ø¨ÛŒØ´ØªØ± Ú©Ø±Ø¯Ù…
            final_description = final_description[:500] + "..."
        elif not final_description: # Ø§Ú¯Ø± ØªÙˆØ¶ÛŒØ­Ø§Øª Ù¾Ø³ Ø§Ø² Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø®Ø§Ù„ÛŒ Ø´Ø¯
            final_description = ""


        # 3. Ù…ÙˆÙ†ØªØ§Ú˜ Ù¾ÛŒØ§Ù…
        # Ø¹Ù†ÙˆØ§Ù† Ø±ÙˆÛŒØ¯Ø§Ø¯ (Ø¯ÛŒÚ¯Ø± "Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¬Ø¯ÛŒØ¯" Ø±Ø§ Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
        message_parts = [f"{RLM}ğŸ“ **{display_title}**"]

        if final_description:
            message_parts.append(f"\n{RLM}{final_description}")

        if event.link:
            # Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ø®ÙˆØ¯ Ù¾Ø³Øª ØªÙ„Ú¯Ø±Ø§Ù…ÛŒ Ø§Ø³Øª Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø­Ø§ÙˆÛŒ Ø¢Ù† Ø§Ø³ØªØŒ Ø´Ø§ÛŒØ¯ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ ØªÚ©Ø±Ø§Ø± Ù†Ø¨Ø§Ø´Ø¯
            # Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†ØŒ Ù„ÛŒÙ†Ú© Ø§ØµÙ„ÛŒ Ø§Ø² ÙÛŒØ¯ Ø±Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…
            message_parts.append(f"\n{RLM}ğŸ”— [Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø§Ù…Ù„]({event.link})")

        # Ù…Ù†Ø¨Ø¹ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ù„ÛŒÙ†Ú© Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… (Ø§Ú¯Ø± Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        if event.source_channel_username:
            message_parts.append(f"\n{RLM}ğŸ“¢ **Ù…Ù†Ø¨Ø¹:** [{event.source_channel}](https://t.me/{event.source_channel_username})")
        else:
            message_parts.append(f"\n{RLM}ğŸ“¢ **Ù…Ù†Ø¨Ø¹:** {event.source_channel}")

        if event.published:
            try:
                # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ±Ù…Øª Ø®ÙˆØ§Ù†Ø§ØªØ± (Ù…Ø«Ø§Ù„: 26 May 2025 - 19:13)
                # feedparser ØªØ§Ø±ÛŒØ® Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª struct_time Ø¯Ø± entry.published_parsed Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
                # ÛŒØ§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø±Ø´ØªÙ‡ Ø®Ø§Ù… Ø±Ø§ ÙØ±Ù…Øª Ú©Ù†ÛŒØ¯
                date_obj = datetime.strptime(event.published, "%a, %d %b %Y %H:%M:%S %Z") #
                # Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ ÙˆÙ‚Øª Ù…Ø­Ù„ÛŒ ÛŒØ§ ÛŒÚ© ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (GMT Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø®ÙˆØ¨ Ø§Ø³Øª)
                formatted_date = date_obj.strftime("%d %b %Y - %H:%M %Z")
                message_parts.append(f"\n{RLM}ğŸ“… **Ø§Ù†ØªØ´Ø§Ø±:** {formatted_date}")
            except ValueError:
                # Ø§Ú¯Ø± ÙØ±Ù…Øª ØªØ§Ø±ÛŒØ® Ù…ØªÙØ§ÙˆØª Ø¨ÙˆØ¯ØŒ Ù‡Ù…Ø§Ù† Ø±Ø´ØªÙ‡ Ø®Ø§Ù… Ø±Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† Ø«Ø§Ù†ÛŒÙ‡)
                message_parts.append(f"\n{RLM}ğŸ“… **Ø§Ù†ØªØ´Ø§Ø±:** {event.published.split(',')[1].strip().rsplit(':',1)[0]} GMT")


        return "\n".join(message_parts).strip() # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© \n Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù†ØŒ Ù†Ù‡ Ø¯ÙˆØªØ§ Ù…Ú¯Ø± Ø¨Ø¹Ø¯ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ


    async def publish_event(self, event: EventInfo):
        """Publish event to Telegram channel"""
        try:
            message = self.format_event_message(event)
            if not message: # Ø§Ú¯Ø± Ù¾ÛŒØ§Ù… Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ (Ù…Ø«Ù„Ø§ ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø§Ø³Ø¨ÛŒ Ù†Ø¯Ø§Ø´Øª)
                logger.info(f"Skipping empty message for an event from {event.source_channel}.")
                return

            await self.bot.send_message(
                chat_id=self.target_channel,
                text=message,
                parse_mode='Markdown', # MarkdownV2 Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ØªØ± Ø§Ø³Øª Ø§Ù…Ø§ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯
                disable_web_page_preview=False # Ø§Ø¬Ø§Ø²Ù‡ Ø¨Ù‡ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
            )
            logger.info(f"Published event: {event.title[:50]}... from {event.source_channel}")
        except Exception as e:
            logger.error(f"Failed to publish event ({event.title[:50]}...): {e}", exc_info=True)

    async def run_monitoring_loop(self):
        """Main monitoring loop"""
        logger.info("Starting RSS monitoring...")
        
        # Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§: Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯ ØªØ§ Ø´Ø¨Ú©Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø´ÙˆØ¯ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
        await asyncio.sleep(5)

        while True:
            logger.info("Checking all feeds...")
            all_new_events = []
            async with aiohttp.ClientSession() as session:
                tasks = [self.fetch_feed(session, feed_info) for feed_info in self.rss_feeds]
                results = await asyncio.gather(*tasks, return_exceptions=True)

                for result in results:
                    if isinstance(result, list):
                        all_new_events.extend(result)
                    elif isinstance(result, Exception):
                        logger.error(f"Feed processing task error: {result}", exc_info=result)
            
            if all_new_events:
                logger.info(f"Found {len(all_new_events)} new event(s) to publish.")
                # Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ù‡ ØªØ±ØªÛŒØ¨ ØªØ§Ø±ÛŒØ® Ø§Ù†ØªØ´Ø§Ø± Ù…Ø±ØªØ¨ Ú©Ù†ÛŒØ¯ (Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª Ùˆ ØªØ§Ø±ÛŒØ® Ù‚Ø§Ø¨Ù„ Ø§ØªÚ©Ø§Ø³Øª)
                # all_new_events.sort(key=lambda x: x.published_parsed_object_or_default, reverse=False)
                
                for event_to_publish in all_new_events:
                    await self.publish_event(event_to_publish)
                    await asyncio.sleep(3)  # ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ„Ú¯Ø±Ø§Ù…
            else:
                logger.info("No new events found in this cycle.")

            # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ
            check_interval_seconds = 600 # 10 Ø¯Ù‚ÛŒÙ‚Ù‡
            logger.info(f"Next check in {check_interval_seconds // 60} minutes.")
            await asyncio.sleep(check_interval_seconds)


class Config:
    BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
    TARGET_CHANNEL = os.getenv('TARGET_CHANNEL') # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯Ù… ØªØ§ Ø­ØªÙ…Ø§ Ø§Ø² Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´ÙˆØ¯

async def health_check(request):
    """Health check endpoint for Hugging Face Spaces"""
    # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯ØŒ Ù…Ø«Ù„Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
    return web.Response(text=f"Bot is running! Processed items in memory: {len(rss_bot.processed_items if 'rss_bot' in globals() else 0)}", status=200)

async def start_web_server():
    """Start web server for health checks"""
    app = web.Application()
    app.router.add_get('/health', health_check)
    app.router.add_get('/', health_check) # Ø±ÙˆØª Ø§ØµÙ„ÛŒ Ø±Ø§ Ù‡Ù… Ø¨Ù‡ health check ÙˆØµÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…

    runner = web.AppRunner(app)
    await runner.setup()
    # Ù¾ÙˆØ±Øª Ø±Ø§ Ø§Ø² Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ PORT Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯ Ú©Ù‡ ØªÙˆØ³Ø· Ù‡Ø§Ú¯ÛŒÙ†Ú¯ ÙÛŒØ³ Ø§Ø³Ù¾ÛŒØ³ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´ÙˆØ¯
    # Ø§Ú¯Ø± ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø¨ÙˆØ¯ØŒ Ø§Ø² 7860 Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    port = int(os.environ.get("PORT", "7860"))
    site = web.TCPSite(runner, '0.0.0.0', port)
    try:
        await site.start()
        logger.info(f"Web server started on port {port}")
    except OSError as e:
        logger.error(f"Failed to start web server on port {port}: {e}. Ensure the port is free or try another.")
        # Ø§Ú¯Ø± ÙˆØ¨ Ø³Ø±ÙˆØ± Ø­ÛŒØ§ØªÛŒ Ù†ÛŒØ³ØªØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø¯ÙˆÙ† Ø¢Ù† Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯ ÛŒØ§ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯
        # raise # Ø¨Ø±Ø§ÛŒ Ù…ØªÙˆÙ‚Ù Ú©Ø±Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡

# Ú¯Ù„ÙˆØ¨Ø§Ù„ Ú©Ø±Ø¯Ù† Ø±Ø¨Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø± health_check
rss_bot: Optional[RSSTelegramBot] = None

async def main():
    global rss_bot # Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø±Ø¨Ø§Øª Ø¯Ø± health_check

    if not Config.BOT_TOKEN:
        logger.error("TELEGRAM_BOT_TOKEN environment variable is required!")
        return
    if not Config.TARGET_CHANNEL:
        logger.error("TARGET_CHANNEL environment variable is required!")
        return
    
    logger.info("Application starting...")

    # Create bot instance
    rss_bot = RSSTelegramBot(
        bot_token=Config.BOT_TOKEN,
        target_channel=Config.TARGET_CHANNEL
    )

    try:
        # Test bot connection
        bot_info = await rss_bot.bot.get_me()
        logger.info(f"Bot started: @{bot_info.username}")

        # Start web server for health checks (Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ Ø±Ø¨Ø§Øª)
        # ÙˆØ¨ Ø³Ø±ÙˆØ± Ø±Ø§ Ø¯Ø± ÛŒÚ© ØªØ³Ú© Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯ ØªØ§ Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª Ø¨Ù„Ø§Ú© Ù†Ø´ÙˆØ¯
        web_server_task = asyncio.create_task(start_web_server())
        
        # Start monitoring
        await rss_bot.run_monitoring_loop()
        
    except KeyboardInterrupt:
        logger.info("Bot stopped by user (KeyboardInterrupt)")
    except Exception as e:
        logger.error(f"Critical bot error: {e}", exc_info=True)
    finally:
        logger.info("Bot shutting down...")
        if 'web_server_task' in locals() and not web_server_task.done():
            web_server_task.cancel() # Ø¯Ø± ØµÙˆØ±Øª Ø§ØªÙ…Ø§Ù… Ú©Ø§Ø±ØŒ ÙˆØ¨ Ø³Ø±ÙˆØ± Ø±Ø§ Ù‡Ù… Ù…ØªÙˆÙ‚Ù Ú©Ù†ÛŒØ¯
            try:
                await web_server_task
            except asyncio.CancelledError:
                logger.info("Web server task cancelled.")


if __name__ == "__main__":
    # Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Ctrl+C Ø¯Ø± ÙˆÛŒÙ†Ø¯ÙˆØ² Ùˆ Ù¾Ø§ÛŒØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ±
    # loop = asyncio.get_event_loop()
    # try:
    #     loop.run_until_complete(main())
    # except KeyboardInterrupt:
    #     logger.info("Application shutting down (KeyboardInterrupt caught in __main__)...")
    # finally:
    #     # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡ÛŒØ¯
    #     # tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]
    #     # [task.cancel() for task in tasks]
    #     # loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))
    #     # loop.close()
    #     logger.info("Application fully stopped.")
    asyncio.run(main())
